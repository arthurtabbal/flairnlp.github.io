"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[8841],{3905:(e,t,n)=>{n.d(t,{Zo:()=>c,kt:()=>u});var a=n(7294);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,i=function(e,t){if(null==e)return{};var n,a,i={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var o=a.createContext({}),p=function(e){var t=a.useContext(o),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},c=function(e){var t=p(e.components);return a.createElement(o.Provider,{value:t},e.children)},d="mdxType",g={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef((function(e,t){var n=e.components,i=e.mdxType,r=e.originalType,o=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),d=p(n),m=i,u=d["".concat(o,".").concat(m)]||d[m]||g[m]||r;return n?a.createElement(u,s(s({ref:t},c),{},{components:n})):a.createElement(u,s({ref:t},c))}));function u(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var r=n.length,s=new Array(r);s[0]=m;var l={};for(var o in t)hasOwnProperty.call(t,o)&&(l[o]=t[o]);l.originalType=e,l[d]="string"==typeof e?e:i,s[1]=l;for(var p=2;p<r;p++)s[p]=n[p];return a.createElement.apply(null,s)}return a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},3460:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>o,contentTitle:()=>s,default:()=>g,frontMatter:()=>r,metadata:()=>l,toc:()=>p});var a=n(7462),i=(n(7294),n(3905));const r={sidebar_position:4,description:"How to do sentiment analysis on your text"},s="Tagging sentiment",l={unversionedId:"tutorial-basics/tagging-sentiment",id:"tutorial-basics/tagging-sentiment",title:"Tagging sentiment",description:"How to do sentiment analysis on your text",source:"@site/docs/tutorial-basics/tagging-sentiment.md",sourceDirName:"tutorial-basics",slug:"/tutorial-basics/tagging-sentiment",permalink:"/docs/tutorial-basics/tagging-sentiment",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/tutorial-basics/tagging-sentiment.md",tags:[],version:"current",sidebarPosition:4,frontMatter:{sidebar_position:4,description:"How to do sentiment analysis on your text"},sidebar:"tutorialSidebar",previous:{title:"Tagging entities",permalink:"/docs/tutorial-basics/tagging-entities"},next:{title:"Tagging and linking entities",permalink:"/docs/tutorial-basics/entity-linking"}},o={},p=[{value:"Tagging Sentiment - Fast",id:"tagging-sentiment---fast",level:2},{value:"Understanding and Accessing Annotations (important!)",id:"understanding-and-accessing-annotations-important",level:2},{value:"Tagging a Whole Text Corpus",id:"tagging-a-whole-text-corpus",level:2},{value:"List of Sentiment Models",id:"list-of-sentiment-models",level:3}],c={toc:p},d="wrapper";function g(e){let{components:t,...n}=e;return(0,i.kt)(d,(0,a.Z)({},c,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"tagging-sentiment"},"Tagging sentiment"),(0,i.kt)("p",null,"Our standard sentiment analysis model uses distilBERT embeddings and was trained over a mix of corpora, notably\nthe Amazon review corpus, and can thus handle a variety of domains and language."),(0,i.kt)("p",null,"Let's use an example sentence:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"from flair.nn import Classifier\nfrom flair.data import Sentence\n\n# load the model\ntagger = Classifier.load('sentiment')\n\n# make a sentence\nsentence = Sentence('This movie is not at all bad.')\n\n# predict NER tags\ntagger.predict(sentence)\n\n# print sentence with predicted tags\nprint(sentence)\n")),(0,i.kt)("p",null,"This should print:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-console"},'Sentence[8]: "This movie is not at all bad." \u2192 POSITIVE (0.9929)\n')),(0,i.kt)("p",null,"Showing us that the sentence overall is tagged to be of POSITIVE sentiment. "),(0,i.kt)("h2",{id:"tagging-sentiment---fast"},"Tagging Sentiment - Fast"),(0,i.kt)("p",null,"We also offer an RNN-based variant which is faster but less accurate. Use it like this: "),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"from flair.nn import Classifier\nfrom flair.data import Sentence\n\n# load the model\ntagger = Classifier.load('sentiment-fast')\n\n# make a sentence\nsentence = Sentence('This movie is very bad.')\n\n# predict NER tags\ntagger.predict(sentence)\n\n# print sentence with predicted tags\nprint(sentence)\n")),(0,i.kt)("p",null,"This should print:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-console"},'Sentence[6]: "This movie is very bad." \u2192 NEGATIVE (0.9999)\n')),(0,i.kt)("p",null,"This indicates that the sentence is of NEGATIVE sentiment. As you can see, its the same code as above, just loading the\n'",(0,i.kt)("strong",{parentName:"p"},"sentiment-fast"),"' model instead of '",(0,i.kt)("strong",{parentName:"p"},"sentiment"),"'."),(0,i.kt)("h2",{id:"understanding-and-accessing-annotations-important"},"Understanding and Accessing Annotations (important!)"),(0,i.kt)("p",null,"You can access each prediction individually using the ",(0,i.kt)("inlineCode",{parentName:"p"},"get_labels()")," method. "),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"from flair.nn import Classifier\nfrom flair.data import Sentence\n\n# load the model\ntagger = Classifier.load('sentiment')\n\n# make a sentence\nsentence = Sentence('This movie is not at all bad.')\n\n# predict NER tags\ntagger.predict(sentence)\n")),(0,i.kt)("p",null,"Use the ",(0,i.kt)("inlineCode",{parentName:"p"},"get_labels()")," method to iterate over all predictions. Direct access each label's value (predicted tag)\nand its confidence score."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"# Use the `get_labels()` method to iterate over all predictions. \nfor label in sentence.get_labels():\n    print(label)\n    # print label value and score\n    print(f'label.value is: \"{label.value}\"')\n    print(f'label.score is: \"{label.score}\"')\n")),(0,i.kt)("p",null,"Since there is only one prediction, this should print:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-console"},'Sentence[8]: "This movie is not at all bad." \u2192 POSITIVE (0.9929)\nlabel.value is: "POSITIVE"\nlabel.score is: "0.9928739070892334"\n')),(0,i.kt)("h2",{id:"tagging-a-whole-text-corpus"},"Tagging a Whole Text Corpus"),(0,i.kt)("p",null,"Often, you may want to tag an entire text corpus. In this case, you need to split the corpus into sentences and pass a\nlist of ",(0,i.kt)("inlineCode",{parentName:"p"},"Sentence")," objects to the ",(0,i.kt)("inlineCode",{parentName:"p"},".predict()")," method."),(0,i.kt)("p",null,"For instance, you can use the sentence splitter of segtok to split your text:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"from flair.nn import Classifier\nfrom flair.splitter import SegtokSentenceSplitter\n\n# example text with many sentences\ntext = \"I first thought it was great. Then I realized it's terrible. But I came to the conclusion that it's great.\"\n\n# initialize sentence splitter\nsplitter = SegtokSentenceSplitter()\n\n# use splitter to split text into list of sentences\nsentences = splitter.split(text)\n\n# predict tags for sentences\ntagger = Classifier.load('sentiment')\ntagger.predict(sentences)\n\n# iterate through sentences and print predicted labels\nfor sentence in sentences:\n    print(sentence)\n")),(0,i.kt)("p",null,"This should print: "),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-console"},'Sentence[7]: "I first thought it was great." \u2192 POSITIVE (0.6549)\nSentence[7]: "Then I realized it\'s terrible." \u2192 NEGATIVE (1.0)\nSentence[11]: "But I came to the conclusion that it\'s great." \u2192 POSITIVE (0.9846)\n')),(0,i.kt)("p",null,"Using the ",(0,i.kt)("inlineCode",{parentName:"p"},"mini_batch_size")," parameter of the ",(0,i.kt)("inlineCode",{parentName:"p"},".predict()")," method, you can set the size of mini batches passed to the\ntagger. Depending on your resources, you might want to play around with this parameter to optimize speed."),(0,i.kt)("h3",{id:"list-of-sentiment-models"},"List of Sentiment Models"),(0,i.kt)("p",null,"We end this section with a list of all models we currently ship with Flair:"),(0,i.kt)("table",null,(0,i.kt)("thead",{parentName:"table"},(0,i.kt)("tr",{parentName:"thead"},(0,i.kt)("th",{parentName:"tr",align:null},"ID"),(0,i.kt)("th",{parentName:"tr",align:null},"Language"),(0,i.kt)("th",{parentName:"tr",align:null},"Task"),(0,i.kt)("th",{parentName:"tr",align:null},"Training Dataset"),(0,i.kt)("th",{parentName:"tr",align:null},"Accuracy"))),(0,i.kt)("tbody",{parentName:"table"},(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"'sentiment'"),(0,i.kt)("td",{parentName:"tr",align:null},"English"),(0,i.kt)("td",{parentName:"tr",align:null},"detecting positive and negative sentiment (transformer-based)"),(0,i.kt)("td",{parentName:"tr",align:null},"movie and product reviews"),(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("strong",{parentName:"td"},"98.87"))),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"'sentiment-fast'"),(0,i.kt)("td",{parentName:"tr",align:null},"English"),(0,i.kt)("td",{parentName:"tr",align:null},"detecting positive and negative sentiment (RNN-based)"),(0,i.kt)("td",{parentName:"tr",align:null},"movie and product reviews"),(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("strong",{parentName:"td"},"96.83"))),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"'de-offensive-language'"),(0,i.kt)("td",{parentName:"tr",align:null},"German"),(0,i.kt)("td",{parentName:"tr",align:null},"detecting offensive language"),(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("a",{parentName:"td",href:"https://projects.fzai.h-da.de/iggsa/projekt/"},"GermEval 2018 Task 1")),(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("strong",{parentName:"td"},"75.71")," (Macro F1)")))))}g.isMDXComponent=!0}}]);