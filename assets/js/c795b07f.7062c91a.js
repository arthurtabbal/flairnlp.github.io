"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[8841],{3905:(e,t,n)=>{n.d(t,{Zo:()=>m,kt:()=>u});var a=n(7294);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,i=function(e,t){if(null==e)return{};var n,a,i={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var o=a.createContext({}),d=function(e){var t=a.useContext(o),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},m=function(e){var t=d(e.components);return a.createElement(o.Provider,{value:t},e.children)},g="mdxType",p={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},c=a.forwardRef((function(e,t){var n=e.components,i=e.mdxType,r=e.originalType,o=e.parentName,m=l(e,["components","mdxType","originalType","parentName"]),g=d(n),c=i,u=g["".concat(o,".").concat(c)]||g[c]||p[c]||r;return n?a.createElement(u,s(s({ref:t},m),{},{components:n})):a.createElement(u,s({ref:t},m))}));function u(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var r=n.length,s=new Array(r);s[0]=c;var l={};for(var o in t)hasOwnProperty.call(t,o)&&(l[o]=t[o]);l.originalType=e,l[g]="string"==typeof e?e:i,s[1]=l;for(var d=2;d<r;d++)s[d]=n[d];return a.createElement.apply(null,s)}return a.createElement.apply(null,n)}c.displayName="MDXCreateElement"},3460:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>o,contentTitle:()=>s,default:()=>p,frontMatter:()=>r,metadata:()=>l,toc:()=>d});var a=n(7462),i=(n(7294),n(3905));const r={sidebar_position:4,description:"Sentiment analysis with Flair"},s="Tagging sentiment",l={unversionedId:"tutorial-basics/tagging-sentiment",id:"tutorial-basics/tagging-sentiment",title:"Tagging sentiment",description:"Sentiment analysis with Flair",source:"@site/docs/tutorial-basics/tagging-sentiment.md",sourceDirName:"tutorial-basics",slug:"/tutorial-basics/tagging-sentiment",permalink:"/docs/tutorial-basics/tagging-sentiment",draft:!1,editUrl:"https://github.com/flairNLP/flairnlp.github.io/edit/source/docs/tutorial-basics/tagging-sentiment.md",tags:[],version:"current",sidebarPosition:4,frontMatter:{sidebar_position:4,description:"Sentiment analysis with Flair"},sidebar:"tutorialSidebar",previous:{title:"Tagging entities",permalink:"/docs/tutorial-basics/tagging-entities"},next:{title:"Tagging and linking entities",permalink:"/docs/tutorial-basics/entity-linking"}},o={},d=[{value:"Tagging sentiment with our standard model",id:"tagging-sentiment-with-our-standard-model",level:2},{value:"Tagging sentiment with our fast model",id:"tagging-sentiment-with-our-fast-model",level:2},{value:"List of Sentiment Models",id:"list-of-sentiment-models",level:2}],m={toc:d},g="wrapper";function p(e){let{components:t,...n}=e;return(0,i.kt)(g,(0,a.Z)({},m,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"tagging-sentiment"},"Tagging sentiment"),(0,i.kt)("p",null,"This tutorials shows you how to do sentiment analysis in Flair."),(0,i.kt)("h2",{id:"tagging-sentiment-with-our-standard-model"},"Tagging sentiment with our standard model"),(0,i.kt)("p",null,"Our standard sentiment analysis model uses distilBERT embeddings and was trained over a mix of corpora, notably\nthe Amazon review corpus, and can thus handle a variety of domains and language."),(0,i.kt)("p",null,"Let's use an example sentence:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"from flair.nn import Classifier\nfrom flair.data import Sentence\n\n# load the model\ntagger = Classifier.load('sentiment')\n\n# make a sentence\nsentence = Sentence('This movie is not at all bad.')\n\n# predict NER tags\ntagger.predict(sentence)\n\n# print sentence with predicted tags\nprint(sentence)\n")),(0,i.kt)("p",null,"This should print:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-console"},'Sentence[8]: "This movie is not at all bad." \u2192 POSITIVE (0.9929)\n')),(0,i.kt)("p",null,"Showing us that the sentence overall is tagged to be of POSITIVE sentiment. "),(0,i.kt)("h2",{id:"tagging-sentiment-with-our-fast-model"},"Tagging sentiment with our fast model"),(0,i.kt)("p",null,"We also offer an RNN-based variant which is faster but less accurate. Use it like this: "),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"from flair.nn import Classifier\nfrom flair.data import Sentence\n\n# load the model\ntagger = Classifier.load('sentiment-fast')\n\n# make a sentence\nsentence = Sentence('This movie is very bad.')\n\n# predict NER tags\ntagger.predict(sentence)\n\n# print sentence with predicted tags\nprint(sentence)\n")),(0,i.kt)("p",null,"This should print:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-console"},'Sentence[6]: "This movie is very bad." \u2192 NEGATIVE (0.9999)\n')),(0,i.kt)("p",null,"This indicates that the sentence is of NEGATIVE sentiment. As you can see, its the same code as above, just loading the\n'",(0,i.kt)("strong",{parentName:"p"},"sentiment-fast"),"' model instead of '",(0,i.kt)("strong",{parentName:"p"},"sentiment"),"'."),(0,i.kt)("h2",{id:"list-of-sentiment-models"},"List of Sentiment Models"),(0,i.kt)("p",null,"We end this section with a list of all models we currently ship with Flair:"),(0,i.kt)("table",null,(0,i.kt)("thead",{parentName:"table"},(0,i.kt)("tr",{parentName:"thead"},(0,i.kt)("th",{parentName:"tr",align:null},"ID"),(0,i.kt)("th",{parentName:"tr",align:null},"Language"),(0,i.kt)("th",{parentName:"tr",align:null},"Task"),(0,i.kt)("th",{parentName:"tr",align:null},"Training Dataset"),(0,i.kt)("th",{parentName:"tr",align:null},"Accuracy"))),(0,i.kt)("tbody",{parentName:"table"},(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"'sentiment'"),(0,i.kt)("td",{parentName:"tr",align:null},"English"),(0,i.kt)("td",{parentName:"tr",align:null},"detecting positive and negative sentiment (transformer-based)"),(0,i.kt)("td",{parentName:"tr",align:null},"movie and product reviews"),(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("strong",{parentName:"td"},"98.87"))),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"'sentiment-fast'"),(0,i.kt)("td",{parentName:"tr",align:null},"English"),(0,i.kt)("td",{parentName:"tr",align:null},"detecting positive and negative sentiment (RNN-based)"),(0,i.kt)("td",{parentName:"tr",align:null},"movie and product reviews"),(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("strong",{parentName:"td"},"96.83"))),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"'de-offensive-language'"),(0,i.kt)("td",{parentName:"tr",align:null},"German"),(0,i.kt)("td",{parentName:"tr",align:null},"detecting offensive language"),(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("a",{parentName:"td",href:"https://projects.fzai.h-da.de/iggsa/projekt/"},"GermEval 2018 Task 1")),(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("strong",{parentName:"td"},"75.71")," (Macro F1)")))))}p.isMDXComponent=!0}}]);