"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[7237],{3905:(e,t,n)=>{n.d(t,{Zo:()=>d,kt:()=>u});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function l(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function o(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var s=a.createContext({}),p=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):l(l({},t),e)),n},d=function(e){var t=p(e.components);return a.createElement(s.Provider,{value:t},e.children)},g="mdxType",c={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,i=e.originalType,s=e.parentName,d=o(e,["components","mdxType","originalType","parentName"]),g=p(n),m=r,u=g["".concat(s,".").concat(m)]||g[m]||c[m]||i;return n?a.createElement(u,l(l({ref:t},d),{},{components:n})):a.createElement(u,l({ref:t},d))}));function u(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=n.length,l=new Array(i);l[0]=m;var o={};for(var s in t)hasOwnProperty.call(t,s)&&(o[s]=t[s]);o.originalType=e,o[g]="string"==typeof e?e:r,l[1]=o;for(var p=2;p<i;p++)l[p]=n[p];return a.createElement.apply(null,l)}return a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},328:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>l,default:()=>c,frontMatter:()=>i,metadata:()=>o,toc:()=>p});var a=n(7462),r=(n(7294),n(3905));const i={sidebar_position:8,description:"Other crazy models we have in Flair"},l="Tagging other things",o={unversionedId:"tutorial-basics/other-models",id:"tutorial-basics/other-models",title:"Tagging other things",description:"Other crazy models we have in Flair",source:"@site/docs/tutorial-basics/other-models.md",sourceDirName:"tutorial-basics",slug:"/tutorial-basics/other-models",permalink:"/docs/tutorial-basics/other-models",draft:!1,editUrl:"https://github.com/flairNLP/flairnlp.github.io/edit/source/docs/tutorial-basics/other-models.md",tags:[],version:"current",sidebarPosition:8,frontMatter:{sidebar_position:8,description:"Other crazy models we have in Flair"},sidebar:"tutorialSidebar",previous:{title:"Tagging parts-of-speech",permalink:"/docs/tutorial-basics/part-of-speech-tagging"},next:{title:"How to tag a whole corpus",permalink:"/docs/tutorial-basics/how-to-tag-corpus"}},s={},p=[{value:"Semantic Frame Detection",id:"semantic-frame-detection",level:2},{value:"Syntactic Chunking",id:"syntactic-chunking",level:2},{value:"Tagging Relations",id:"tagging-relations",level:2},{value:"List of Other Models",id:"list-of-other-models",level:2}],d={toc:p},g="wrapper";function c(e){let{components:t,...n}=e;return(0,r.kt)(g,(0,a.Z)({},d,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"tagging-other-things"},"Tagging other things"),(0,r.kt)("p",null,"This tutorial gives you a tour of ",(0,r.kt)("strong",{parentName:"p"},"other crazy models")," shipped with Flair. These include:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"tagging semantic frames  "),(0,r.kt)("li",{parentName:"ul"},"chunking text"),(0,r.kt)("li",{parentName:"ul"},"relation extraction"),(0,r.kt)("li",{parentName:"ul"},"others")),(0,r.kt)("p",null,"Let's get started! "),(0,r.kt)("h2",{id:"semantic-frame-detection"},"Semantic Frame Detection"),(0,r.kt)("p",null,"For English, we provide a pre-trained model that detects semantic frames in text, trained using Propbank 3.0 frames.\nThis provides a sort of word sense disambiguation for frame evoking words, and we are curious what researchers might\ndo with this."),(0,r.kt)("p",null,"Here's an example:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"from flair.nn import Classifier\nfrom flair.data import Sentence\n\n# load model\ntagger = Classifier.load('frame')\n\n# make English sentence\nsentence = Sentence('George returned to Berlin to return his hat.')\n\n# predict NER tags\ntagger.predict(sentence)\n\n# go through tokens and print predicted frame (if one is predicted)\nfor token in sentence:\n    print(token)\n")),(0,r.kt)("p",null,"This should print:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-console"},'Token[0]: "George"\nToken[1]: "returned" \u2192 return.01 (0.9951)\nToken[2]: "to"\nToken[3]: "Berlin"\nToken[4]: "to"\nToken[5]: "return" \u2192 return.02 (0.6361)\nToken[6]: "his"\nToken[7]: "hat"\nToken[8]: "."\n')),(0,r.kt)("p",null,"As we can see, the frame detector makes a distinction in the sentence between two different meanings of the word 'return'. 'return.01' means returning to a location, while 'return.02' means giving something back."),(0,r.kt)("h2",{id:"syntactic-chunking"},"Syntactic Chunking"),(0,r.kt)("p",null,"For English, we provide a model for chunking verb and noun phrases, trained using CoNLL 2000. "),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"from flair.nn import Classifier\nfrom flair.data import Sentence\n\n# load model\ntagger = Classifier.load('chunk')\n\n# make English sentence\nsentence = Sentence('The quick brown fox jumps over the lazy dog.')\n\n# predict NER tags\ntagger.predict(sentence)\n\n# print the chunks\nfor chunk in sentence.get_labels():\n  print(chunk)\n")),(0,r.kt)("p",null,"This should print:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-console"},'Span[0:4]: "The quick brown fox" \u2192 NP (0.9914)\nSpan[4:5]: "jumps" \u2192 VP (1.0)\nSpan[5:6]: "over" \u2192 PP (0.9967)\nSpan[6:9]: "the lazy dog" \u2192 NP (0.9991)\n')),(0,r.kt)("p",null,'This tells us for instance that "the quick brown fox" and "the lazy dog" form syntactic units in this sentence.'),(0,r.kt)("h2",{id:"tagging-relations"},"Tagging Relations"),(0,r.kt)("p",null,'Relations hold between two entities. For instance, a text like "',(0,r.kt)("em",{parentName:"p"},"George was born in Washington"),'"\nnames two entities and also expresses that there is a born_in relationship between\nboth.'),(0,r.kt)("p",null,"We added an experimental relation extraction model trained over a modified version of TACRED.\nYou must use this model together with an entity tagger. Here is an example:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"from flair.data import Sentence\nfrom flair.nn import Classifier\n\n# 1. make example sentence\nsentence = Sentence(\"George was born in Washington\")\n\n# 2. load entity tagger and predict entities\ntagger = Classifier.load('ner-fast')\ntagger.predict(sentence)\n\n# check which named entities have been found in the sentence\nentities = sentence.get_labels('ner')\nfor entity in entities:\n    print(entity)\n\n# 3. load relation extractor\nextractor = Classifier.load('relations')\n\n# predict relations\nextractor.predict(sentence)\n\n# check which relations have been found\nrelations = sentence.get_labels('relation')\nfor relation in relations:\n    print(relation)\n\n# Use the `get_labels()` method with parameter 'relation' to iterate over all relation predictions. \nfor label in sentence.get_labels('relation'):\n    print(label)\n")),(0,r.kt)("p",null,"This should print:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-console"},'Span[0:1]: "George" \u2192 PER (0.9971)\nSpan[4:5]: "Washington" \u2192 LOC (0.9847)\n\nRelation[0:1][4:5]: "George -> Washington" \u2192 born_in (1.0)\n')),(0,r.kt)("p",null,"Indicating that a ",(0,r.kt)("strong",{parentName:"p"},"born_in"),' relationship holds between "George" and "Washington"!'),(0,r.kt)("h2",{id:"list-of-other-models"},"List of Other Models"),(0,r.kt)("p",null,"We end this section with a list of all other models we currently ship with Flair:"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"ID"),(0,r.kt)("th",{parentName:"tr",align:null},"Task"),(0,r.kt)("th",{parentName:"tr",align:null},"Language"),(0,r.kt)("th",{parentName:"tr",align:null},"Training Dataset"),(0,r.kt)("th",{parentName:"tr",align:null},"Accuracy"),(0,r.kt)("th",{parentName:"tr",align:null},"Contributor / Notes"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"'",(0,r.kt)("a",{parentName:"td",href:"https://huggingface.co/flair/chunk-english"},"chunk"),"'"),(0,r.kt)("td",{parentName:"tr",align:null},"Chunking"),(0,r.kt)("td",{parentName:"tr",align:null},"English"),(0,r.kt)("td",{parentName:"tr",align:null},"Conll-2000"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("strong",{parentName:"td"},"96.47")," (F1)"),(0,r.kt)("td",{parentName:"tr",align:null})),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"'",(0,r.kt)("a",{parentName:"td",href:"https://huggingface.co/flair/chunk-english-fast"},"chunk-fast"),"'"),(0,r.kt)("td",{parentName:"tr",align:null},"Chunking"),(0,r.kt)("td",{parentName:"tr",align:null},"English"),(0,r.kt)("td",{parentName:"tr",align:null},"Conll-2000"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("strong",{parentName:"td"},"96.22")," (F1)"),(0,r.kt)("td",{parentName:"tr",align:null},"(fast model)")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"'",(0,r.kt)("a",{parentName:"td",href:"https://huggingface.co/flair/frame-english"},"frame"),"'"),(0,r.kt)("td",{parentName:"tr",align:null},"Frame Detection"),(0,r.kt)("td",{parentName:"tr",align:null},"English"),(0,r.kt)("td",{parentName:"tr",align:null},"Propbank 3.0"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("strong",{parentName:"td"},"97.54")," (F1)"),(0,r.kt)("td",{parentName:"tr",align:null})),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"'",(0,r.kt)("a",{parentName:"td",href:"https://huggingface.co/flair/frame-english-fast"},"frame-fast"),"'"),(0,r.kt)("td",{parentName:"tr",align:null},"Frame Detection"),(0,r.kt)("td",{parentName:"tr",align:null},"English"),(0,r.kt)("td",{parentName:"tr",align:null},"Propbank 3.0"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("strong",{parentName:"td"},"97.31")," (F1)"),(0,r.kt)("td",{parentName:"tr",align:null},"(fast model)")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"'negation-speculation'"),(0,r.kt)("td",{parentName:"tr",align:null},"Negation / speculation"),(0,r.kt)("td",{parentName:"tr",align:null},"English"),(0,r.kt)("td",{parentName:"tr",align:null},"Bioscope"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("strong",{parentName:"td"},"80.2")," (F1)"),(0,r.kt)("td",{parentName:"tr",align:null})),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"'communicative-functions'"),(0,r.kt)("td",{parentName:"tr",align:null},"detecting function of sentence in research paper (BETA)"),(0,r.kt)("td",{parentName:"tr",align:null},"English"),(0,r.kt)("td",{parentName:"tr",align:null},"scholarly papers"),(0,r.kt)("td",{parentName:"tr",align:null}),(0,r.kt)("td",{parentName:"tr",align:null})),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"'de-historic-indirect'"),(0,r.kt)("td",{parentName:"tr",align:null},"historical indirect speech"),(0,r.kt)("td",{parentName:"tr",align:null},"German"),(0,r.kt)("td",{parentName:"tr",align:null},"@redewiedergabe project"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("strong",{parentName:"td"},"87.94")," (F1)"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://github.com/redewiedergabe/tagger"},"redewiedergabe"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"'de-historic-direct'"),(0,r.kt)("td",{parentName:"tr",align:null},"historical direct speech"),(0,r.kt)("td",{parentName:"tr",align:null},"German"),(0,r.kt)("td",{parentName:"tr",align:null},"@redewiedergabe project"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("strong",{parentName:"td"},"87.94")," (F1)"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://github.com/redewiedergabe/tagger"},"redewiedergabe"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"'de-historic-reported'"),(0,r.kt)("td",{parentName:"tr",align:null},"historical reported speech"),(0,r.kt)("td",{parentName:"tr",align:null},"German"),(0,r.kt)("td",{parentName:"tr",align:null},"@redewiedergabe project"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("strong",{parentName:"td"},"87.94")," (F1)"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://github.com/redewiedergabe/tagger"},"redewiedergabe"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"'de-historic-free-indirect'"),(0,r.kt)("td",{parentName:"tr",align:null},"historical free-indirect speech"),(0,r.kt)("td",{parentName:"tr",align:null},"German"),(0,r.kt)("td",{parentName:"tr",align:null},"@redewiedergabe project"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("strong",{parentName:"td"},"87.94")," (F1)"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://github.com/redewiedergabe/tagger"},"redewiedergabe"))))))}c.isMDXComponent=!0}}]);